{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSHfg3O3IoBk",
    "papermill": {
     "duration": 0.025933,
     "end_time": "2021-02-17T11:18:56.970414",
     "exception": false,
     "start_time": "2021-02-17T11:18:56.944481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Approach-<br>- Regular expression clean-up<br>- Spacy Lemmatization<br>- BERT Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:18:57.024833Z",
     "iopub.status.busy": "2021-02-17T11:18:57.024041Z",
     "iopub.status.idle": "2021-02-17T11:19:05.015757Z",
     "shell.execute_reply": "2021-02-17T11:19:05.015155Z"
    },
    "id": "0yFJuNtn4irH",
    "outputId": "72a7f802-b492-4e31-e6df-c8f90ae304a0",
    "papermill": {
     "duration": 8.021084,
     "end_time": "2021-02-17T11:19:05.015969",
     "exception": false,
     "start_time": "2021-02-17T11:18:56.994885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\r\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 123 kB 1.3 MB/s \r\n",
      "\u001b[?25hCollecting pytorch-nlp\r\n",
      "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 90 kB 3.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch-nlp) (4.55.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch-nlp) (1.19.5)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.7.0)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.17.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (2.25.1)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (2020.11.13)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.6)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\r\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (0.3.4)\r\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.5 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (1.20.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.5->boto3->pytorch-pretrained-bert) (1.26.2)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.5->boto3->pytorch-pretrained-bert) (2.8.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.5->boto3->pytorch-pretrained-bert) (1.15.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\r\n",
      "Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\r\n",
      "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:05.080120Z",
     "iopub.status.busy": "2021-02-17T11:19:05.079354Z",
     "iopub.status.idle": "2021-02-17T11:19:13.377703Z",
     "shell.execute_reply": "2021-02-17T11:19:13.376686Z"
    },
    "id": "cGAKI9Pzaw-C",
    "papermill": {
     "duration": 8.332578,
     "end_time": "2021-02-17T11:19:13.378003",
     "exception": false,
     "start_time": "2021-02-17T11:19:05.045425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import regex as re\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForSequenceClassification, BertAdam\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:13.508830Z",
     "iopub.status.busy": "2021-02-17T11:19:13.507993Z",
     "iopub.status.idle": "2021-02-17T11:19:13.686385Z",
     "shell.execute_reply": "2021-02-17T11:19:13.687277Z"
    },
    "id": "A-UuNZe3bg6z",
    "outputId": "4619ace3-a6e5-47bc-de4d-a376a6c6a140",
    "papermill": {
     "duration": 0.261074,
     "end_time": "2021-02-17T11:19:13.687456",
     "exception": false,
     "start_time": "2021-02-17T11:19:13.426382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:13.754529Z",
     "iopub.status.busy": "2021-02-17T11:19:13.753862Z",
     "iopub.status.idle": "2021-02-17T11:19:13.760194Z",
     "shell.execute_reply": "2021-02-17T11:19:13.761123Z"
    },
    "id": "AWR6ApO-eTmy",
    "papermill": {
     "duration": 0.040752,
     "end_time": "2021-02-17T11:19:13.761307",
     "exception": false,
     "start_time": "2021-02-17T11:19:13.720555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set display option\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "seed_val=42\n",
    "tf.random.set_seed(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:14.354941Z",
     "iopub.status.busy": "2021-02-17T11:19:14.354239Z",
     "iopub.status.idle": "2021-02-17T11:19:14.356908Z",
     "shell.execute_reply": "2021-02-17T11:19:14.357294Z"
    },
    "id": "cw3Gpffj5b_L",
    "papermill": {
     "duration": 0.556452,
     "end_time": "2021-02-17T11:19:14.357445",
     "exception": false,
     "start_time": "2021-02-17T11:19:13.800993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjtcUQZtbZJ1",
    "papermill": {
     "duration": 0.027416,
     "end_time": "2021-02-17T11:19:14.413158",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.385742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data Reading and Understanding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:14.475869Z",
     "iopub.status.busy": "2021-02-17T11:19:14.475349Z",
     "iopub.status.idle": "2021-02-17T11:19:14.524851Z",
     "shell.execute_reply": "2021-02-17T11:19:14.523975Z"
    },
    "id": "d-wYtzLgbMDe",
    "outputId": "445ffa88-9a33-4bd3-92c8-5ec3c5b01437",
    "papermill": {
     "duration": 0.084303,
     "end_time": "2021-02-17T11:19:14.524978",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.440675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:14.598288Z",
     "iopub.status.busy": "2021-02-17T11:19:14.597207Z",
     "iopub.status.idle": "2021-02-17T11:19:14.600517Z",
     "shell.execute_reply": "2021-02-17T11:19:14.600087Z"
    },
    "id": "DFjP9kUVb36b",
    "outputId": "6c098834-8a50-4cca-a021-4c5a402d0664",
    "papermill": {
     "duration": 0.047393,
     "end_time": "2021-02-17T11:19:14.600620",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.553227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n",
      "# of training records:  7613\n"
     ]
    }
   ],
   "source": [
    "print (train_df.info())\n",
    "print (\"# of training records: \", len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:14.662278Z",
     "iopub.status.busy": "2021-02-17T11:19:14.661309Z",
     "iopub.status.idle": "2021-02-17T11:19:14.682560Z",
     "shell.execute_reply": "2021-02-17T11:19:14.681733Z"
    },
    "id": "wbvX-eLJPdDD",
    "outputId": "09e30544-c701-4b91-cb90-2c1c46aafb09",
    "papermill": {
     "duration": 0.053532,
     "end_time": "2021-02-17T11:19:14.682684",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.629152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.57034\n",
       "1    0.42966\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see distribution of target labels\n",
    "train_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:14.753027Z",
     "iopub.status.busy": "2021-02-17T11:19:14.752491Z",
     "iopub.status.idle": "2021-02-17T11:19:14.778051Z",
     "shell.execute_reply": "2021-02-17T11:19:14.778466Z"
    },
    "id": "LfMlaKXcrqlf",
    "outputId": "0b8ed689-ec68-4c22-ca9d-4b26d221b91a",
    "papermill": {
     "duration": 0.063338,
     "end_time": "2021-02-17T11:19:14.778595",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.715257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   0     NaN      NaN   \n",
       "1   2     NaN      NaN   \n",
       "2   3     NaN      NaN   \n",
       "3   9     NaN      NaN   \n",
       "4  11     NaN      NaN   \n",
       "\n",
       "                                                                                               text  \n",
       "0                                                                Just happened a terrible car crash  \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.  \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires  \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read test data\n",
    "test_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNpXh7DJdfQa",
    "papermill": {
     "duration": 0.0312,
     "end_time": "2021-02-17T11:19:14.843692",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.812492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Look at few of the tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:14.912953Z",
     "iopub.status.busy": "2021-02-17T11:19:14.912404Z",
     "iopub.status.idle": "2021-02-17T11:19:14.917527Z",
     "shell.execute_reply": "2021-02-17T11:19:14.917091Z"
    },
    "id": "UIX0dSgEdedY",
    "outputId": "2832c539-9960-4d23-8c8c-f31203780269",
    "papermill": {
     "duration": 0.043882,
     "end_time": "2021-02-17T11:19:14.917630",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.873748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()[['text','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nM90rW2xb_pO",
    "papermill": {
     "duration": 0.030608,
     "end_time": "2021-02-17T11:19:14.979828",
     "exception": false,
     "start_time": "2021-02-17T11:19:14.949220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Checking- if features keyword and location are useful and should be retained**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:15.044857Z",
     "iopub.status.busy": "2021-02-17T11:19:15.044087Z",
     "iopub.status.idle": "2021-02-17T11:19:15.055618Z",
     "shell.execute_reply": "2021-02-17T11:19:15.056003Z"
    },
    "id": "12tpRdP7bvmq",
    "outputId": "02e36ec7-ab21-4596-f81f-791d28dfa6f6",
    "papermill": {
     "duration": 0.046712,
     "end_time": "2021-02-17T11:19:15.056129",
     "exception": false,
     "start_time": "2021-02-17T11:19:15.009417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and I wrecked you both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>Three days off from work and they've pretty much all been wrecked hahaha shoutout to my family f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words that wrecked Disney's stock http://t.co/7enNulLKzM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed Great atmosphere at the British Lion gig tonight. Hearing is wrecked. http://t.co/oM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's stock - CNBC http://t.co/N6RBnHMTD4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword  \\\n",
       "31     ablaze   \n",
       "32     ablaze   \n",
       "33     ablaze   \n",
       "34     ablaze   \n",
       "35     ablaze   \n",
       "...       ...   \n",
       "7578  wrecked   \n",
       "7579  wrecked   \n",
       "7580  wrecked   \n",
       "7581  wrecked   \n",
       "7582  wrecked   \n",
       "\n",
       "                                                                                                     text  \n",
       "31                                                @bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C  \n",
       "32                                    We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw  \n",
       "33                     #AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi  \n",
       "34                                                                     Crying out for more! Set me ablaze  \n",
       "35                           On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N  \n",
       "...                                                                                                   ...  \n",
       "7578                                                     @jt_ruff23 @cameronhacker and I wrecked you both  \n",
       "7579  Three days off from work and they've pretty much all been wrecked hahaha shoutout to my family f...  \n",
       "7580        #FX #forex #trading Cramer: Iger's 3 words that wrecked Disney's stock http://t.co/7enNulLKzM  \n",
       "7581  @engineshed Great atmosphere at the British Lion gig tonight. Hearing is wrecked. http://t.co/oM...  \n",
       "7582                     Cramer: Iger's 3 words that wrecked Disney's stock - CNBC http://t.co/N6RBnHMTD4  \n",
       "\n",
       "[7552 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[~train_df['keyword'].isnull()][['keyword', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:15.121975Z",
     "iopub.status.busy": "2021-02-17T11:19:15.121249Z",
     "iopub.status.idle": "2021-02-17T11:19:15.124766Z",
     "shell.execute_reply": "2021-02-17T11:19:15.124382Z"
    },
    "id": "DDYFpXU1cKP-",
    "outputId": "032fa3cc-942a-46cf-b112-a19c327ea762",
    "papermill": {
     "duration": 0.038514,
     "end_time": "2021-02-17T11:19:15.124893",
     "exception": false,
     "start_time": "2021-02-17T11:19:15.086379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFsbTOA_edwk",
    "papermill": {
     "duration": 0.030198,
     "end_time": "2021-02-17T11:19:15.185543",
     "exception": false,
     "start_time": "2021-02-17T11:19:15.155345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dropping the features: keyword and location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:15.251802Z",
     "iopub.status.busy": "2021-02-17T11:19:15.251077Z",
     "iopub.status.idle": "2021-02-17T11:19:15.253744Z",
     "shell.execute_reply": "2021-02-17T11:19:15.253337Z"
    },
    "id": "hVHqL0qgdTDt",
    "papermill": {
     "duration": 0.038106,
     "end_time": "2021-02-17T11:19:15.253875",
     "exception": false,
     "start_time": "2021-02-17T11:19:15.215769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.drop(columns=['keyword', 'location'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgSSd1O6fHBM",
    "papermill": {
     "duration": 0.030056,
     "end_time": "2021-02-17T11:19:15.314063",
     "exception": false,
     "start_time": "2021-02-17T11:19:15.284007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data Cleaning and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:15.379786Z",
     "iopub.status.busy": "2021-02-17T11:19:15.379023Z",
     "iopub.status.idle": "2021-02-17T11:19:17.528958Z",
     "shell.execute_reply": "2021-02-17T11:19:17.527897Z"
    },
    "id": "U85dDbfN-2WI",
    "outputId": "4fa0ec37-cbea-48cf-8b72-28efbea75bc8",
    "papermill": {
     "duration": 2.184,
     "end_time": "2021-02-17T11:19:17.529141",
     "exception": false,
     "start_time": "2021-02-17T11:19:15.345141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 848748.47B/s]\n"
     ]
    }
   ],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:17.619207Z",
     "iopub.status.busy": "2021-02-17T11:19:17.614076Z",
     "iopub.status.idle": "2021-02-17T11:19:17.621728Z",
     "shell.execute_reply": "2021-02-17T11:19:17.621307Z"
    },
    "id": "33iKNpoo4WN-",
    "papermill": {
     "duration": 0.059288,
     "end_time": "2021-02-17T11:19:17.621865",
     "exception": false,
     "start_time": "2021-02-17T11:19:17.562577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "    \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:17.693767Z",
     "iopub.status.busy": "2021-02-17T11:19:17.693005Z",
     "iopub.status.idle": "2021-02-17T11:19:17.695829Z",
     "shell.execute_reply": "2021-02-17T11:19:17.695407Z"
    },
    "id": "MGZ3H3Rx3rlJ",
    "papermill": {
     "duration": 0.042262,
     "end_time": "2021-02-17T11:19:17.695941",
     "exception": false,
     "start_time": "2021-02-17T11:19:17.653679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_characters = {\n",
    "  \"SuruÌ¤\":\"Suruc\",\n",
    "  \"JapÌ_n\":\"Japan\"  ,\n",
    "  \"\\x89ÛÏWhen\":\"When\",\n",
    "  \"å£3million\":\"3 million\",\n",
    "  \"fromåÊwounds\":\"from wounds\",\n",
    "  \"mÌ¼sica\":\"music\",\n",
    "  \"donå«t\":\"do not\",\n",
    "  \"didn`t\":\"did not\",\n",
    "  \"i\\x89Ûªm\":\"I am\",\n",
    "  \"I\\x89Ûªm\":\"I am\",\n",
    "  \"it\\x89Ûªs\":\"it is\",\n",
    "  \"It\\x89Ûªs\":\"It is\",\n",
    "  \"i\\x89Ûªd\":\"I would\",\n",
    "  \"I\\x89Ûªd\":\"I would\",\n",
    "  \"i\\x89Ûªve\":\"I have\",\n",
    "  \"I\\x89Ûªve\":\"I have\",\n",
    "  \"let\\x89Ûªs\":\"let us\",\n",
    "  \"don\\x89Ûªt\":\"do not\",\n",
    "  \"Don\\x89Ûªt\":\"Do not\",\n",
    "  \"can\\x89Ûªt\":\"cannot\",\n",
    "  \"Can\\x89Ûªt\":\"Cannot\",\n",
    "  \"that\\x89Ûªs\":\"that is\",\n",
    "  \"That\\x89Ûªs\":\"That is\",\n",
    "  \"here\\x89Ûªs\":\"here is\",\n",
    "  \"Here\\x89Ûªs\":\"Here is\",\n",
    "  \"you\\x89Ûªre\":\"you are\",\n",
    "  \"You\\x89Ûªre\":\"You are\",\n",
    "  \"you\\x89Ûªve\":\"you have\",\n",
    "  \"You\\x89Ûªve\":\"You have\",\n",
    "  \"you\\x89Ûªll\":\"you will\",\n",
    "  \"You\\x89Ûªll\":\"You will\",\n",
    "  \"China\\x89Ûªs\":\"China's\",\n",
    "  \"doesn\\x89Ûªt\":\"does not\",\n",
    "  \"wouldn\\x89Ûªt\":\"would not\",\n",
    "  \"\\x89Û_\":\"\",\n",
    "  \"\\x89Û¢\":\"\",\n",
    "  \"\\x89ÛÒ\":\"\",\n",
    "  \"\\x89ÛÓ\":\"\",\n",
    "  \"\\x89ÛÏ\":\"\",\n",
    "  \"\\x89Û÷\":\"\",\n",
    "  \"\\x89Ûª\":\"\",\n",
    "  \"\\x89Û¢åÊ\":\"\",\n",
    "  \"\\x89Û\\x9d\":\"\",\n",
    "  \"å_\":\"\",\n",
    "  \"å¨\":\"\",\n",
    "  \"åÀ\":\"\",\n",
    "  \"åÇ\":\"\",\n",
    "  \"åÊ\":\"\",\n",
    "  \"åÈ\":\"\"  ,\n",
    "  \"Ì©\":\"\",\n",
    "  \"&lt;\":\"<\",\n",
    "  \"&gt;\":\">\",\n",
    "  \"&amp;\":\"&\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:17.770552Z",
     "iopub.status.busy": "2021-02-17T11:19:17.769723Z",
     "iopub.status.idle": "2021-02-17T11:19:17.772417Z",
     "shell.execute_reply": "2021-02-17T11:19:17.771900Z"
    },
    "id": "G3J2zcru6_SK",
    "papermill": {
     "duration": 0.045295,
     "end_time": "2021-02-17T11:19:17.772519",
     "exception": false,
     "start_time": "2021-02-17T11:19:17.727224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "expand_contractions = {\n",
    "  \"I'm\":\"I am\",\n",
    "  \"I'M\":\"I am\",\n",
    "  \"i'm\":\"I am\",\n",
    "  \"i'M\":\"I am\",\n",
    "  \"i'd\":\"I would\",\n",
    "  \"I'd\":\"I would\",\n",
    "  \"i'll\":\"I will\",\n",
    "  \"I'll\":\"I will\",\n",
    "  \"i've\":\"I have\",\n",
    "  \"I've\":\"I have\",\n",
    "  \"you're\":\"you are\",\n",
    "  \"You're\":\"You are\",\n",
    "  \"you'd\":\"you would\",\n",
    "  \"You'd\":\"You would\",\n",
    "  \"you've\":\"you have\",\n",
    "  \"You've\":\"You have\",\n",
    "  \"you'll\":\"you will\",\n",
    "  \"You'll\":\"You will\"  ,\n",
    "  \"y'know\":\"you know\"  ,\n",
    "  \"Y'know\":\"You know\"  ,\n",
    "  \"y'all\":\"you all\",\n",
    "  \"Y'all\":\"You all\",\n",
    "  \"we're\":\"we are\",\n",
    "  \"We're\":\"We are\",\n",
    "  \"we've\":\"we have\",\n",
    "  \"We've\":\"We have\" ,\n",
    "  \"we'd\":\"we would\",\n",
    "  \"We'd\":\"We would\",\n",
    "  \"WE'VE\":\"We have\",\n",
    "  \"we'll\":\"we will\",\n",
    "  \"We'll\":\"We will\",\n",
    "  \"they're\":\"they are\",\n",
    "  \"They're\":\"They are\",\n",
    "  \"they'd\":\"they would\",\n",
    "  \"They'd\":\"They would\"  ,\n",
    "  \"they've\":\"they have\",\n",
    "  \"They've\":\"They have\",\n",
    "  \"they'll\":\"they will\",\n",
    "  \"They'll\":\"They will\",\n",
    "  \"he's\":\"he is\",\n",
    "  \"He's\":\"He is\",\n",
    "  \"he'll\":\"he will\",\n",
    "  \"He'll\":\"He will\",\n",
    "  \"she's\":\"she is\",\n",
    "  \"She's\":\"She is\",\n",
    "  \"she'll\":\"she will\",\n",
    "  \"She'll\":\"She will\",\n",
    "  \"it's\":\"it is\",\n",
    "  \"It's\":\"It is\",\n",
    "  \"it'll\":\"it will\",\n",
    "  \"It'll\":\"It will\",\n",
    "  \"isn't\":\"is not\",\n",
    "  \"Isn't\":\"Is not\",\n",
    "  \"who's\":\"who is\",\n",
    "  \"Who's\":\"Who is\",\n",
    "  \"what's\":\"what is\",\n",
    "  \"What's\":\"What is\",\n",
    "  \"that's\":\"that is\",\n",
    "  \"That's\":\"That is\",\n",
    "  \"here's\":\"here is\",\n",
    "  \"Here's\":\"Here is\",\n",
    "  \"there's\":\"there is\",\n",
    "  \"There's\":\"There is\",\n",
    "  \"where's\":\"where is\",\n",
    "  \"Where's\":\"Where is\"  ,\n",
    "  \"wHeRE's\":\"where is\" ,\n",
    "  \"how's\":\"how is\"  ,\n",
    "  \"How's\":\"How is\"  ,\n",
    "  \"how're\":\"how are\"  ,\n",
    "  \"How're\":\"How are\" ,\n",
    "  \"let's\":\"let us\",\n",
    "  \"Let's\":\"Let us\",\n",
    "  \"won't\":\"will not\",\n",
    "  \"wasn't\":\"was not\",\n",
    "  \"aren't\":\"are not\",\n",
    "  \"couldn't\":\"could not\",\n",
    "  \"shouldn't\":\"should not\",\n",
    "  \"haven't\":\"have not\",\n",
    "  \"Haven't\":\"Have not\",\n",
    "  \"hasn't\":\"has not\",\n",
    "  \"wouldn't\":\"would not\",\n",
    "  \"weren't\":\"were not\",\n",
    "  \"Weren't\":\"Were not\",\n",
    "  \"ain't\":\"am not\",\n",
    "  \"Ain't\":\"am not\",\n",
    "  \"don't\":\"do not\",\n",
    "  \"Don't\":\"do not\",\n",
    "  \"DON'T\":\"Do not\",\n",
    "  \"didn't\":\"did not\",\n",
    "  \"Didn't\":\"Did not\",\n",
    "  \"DIDN'T\":\"Did not\",\n",
    "  \"doesn't\":\"does not\",\n",
    "  \"can't\":\"cannot\",\n",
    "  \"Can't\":\"Cannot\",\n",
    "  \"Could've\":\"Could have\",\n",
    "  \"should've\":\"should have\",\n",
    "  \"would've\":\"would have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:17.840825Z",
     "iopub.status.busy": "2021-02-17T11:19:17.840228Z",
     "iopub.status.idle": "2021-02-17T11:19:17.843326Z",
     "shell.execute_reply": "2021-02-17T11:19:17.842931Z"
    },
    "id": "V6QiX2ey9jhQ",
    "papermill": {
     "duration": 0.038921,
     "end_time": "2021-02-17T11:19:17.843443",
     "exception": false,
     "start_time": "2021-02-17T11:19:17.804522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "informal_abbreviations = {\n",
    "  \"b/c\":\"because\",\n",
    "  \"w/e\":\"whatever\",\n",
    "  \"w/out\":\"without\",\n",
    "  \"w/o\":\"without\",\n",
    "  \"w/\":\"with \",\n",
    "  \"<3\":\"love\",\n",
    "  \"c/o\":\"care of\",\n",
    "  \"p/u\":\"pick up\",\n",
    "  \"\\n\":\" \"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:17.912777Z",
     "iopub.status.busy": "2021-02-17T11:19:17.912129Z",
     "iopub.status.idle": "2021-02-17T11:19:17.914908Z",
     "shell.execute_reply": "2021-02-17T11:19:17.914489Z"
    },
    "id": "p0Lh2ceb_yPN",
    "papermill": {
     "duration": 0.039843,
     "end_time": "2021-02-17T11:19:17.915016",
     "exception": false,
     "start_time": "2021-02-17T11:19:17.875173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "smileys = {\n",
    "  \"\\:33333\" : \"smile\",    # :33333\n",
    "  \"\\:\\)\\)\\)\\)\" : \"smile\", # :))))\n",
    "  \"\\:\\)\\)\\)\" : \"smile\", # :)))\n",
    "  \"\\:\\)\\)\" : \"smile\",   # :))\n",
    "  \"\\:-\\)\" : \"smile\",   # :-)\n",
    "  \"\\;-\\)\" : \"smile\",   # ;-)\n",
    "  \"3\\-D\" : \"smile\",  # 3-D\n",
    "  \"\\:O\" : \"smile\",   # :O\n",
    "  \"\\:D\" : \"smile\",   # :D\n",
    "  \"\\:P\" : \"smile\",   # :P\n",
    "  \"\\:p\" : \"smile\",   # :p\n",
    "  \"\\;\\)\" : \"smile\",  # ;)\n",
    "  \"\\:\\)\" : \"smile\",  # :)\n",
    "  \"\\=\\)\" : \"smile\",  # =)\n",
    "  \"\\^\\^\" : \"smile\",  # ^^\n",
    "  \"\\:-\\(\" : \"sad\",   # :-(\n",
    "  \"\\:\\(\" : \"sad\",    # :(\n",
    "  \"\\=\\(\" : \"sad\",    # =(\n",
    "  \"\\-\\_\\_\\-\" : \"\",   # -__-\n",
    "  \"\\.\\_\\.\" : \"\",     # ._.\n",
    "  \"T\\_T\" : \"\",       # T_T    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:17.988522Z",
     "iopub.status.busy": "2021-02-17T11:19:17.987839Z",
     "iopub.status.idle": "2021-02-17T11:19:17.990292Z",
     "shell.execute_reply": "2021-02-17T11:19:17.990694Z"
    },
    "id": "DTgZ8OY7_KtK",
    "papermill": {
     "duration": 0.044084,
     "end_time": "2021-02-17T11:19:17.990823",
     "exception": false,
     "start_time": "2021-02-17T11:19:17.946739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):  \n",
    "  cleaned_text = text.lower()\n",
    "  \n",
    "  #substitute web address with string \"URL\"\n",
    "  cleaned_text = re.sub(r'https?:\\S+|www\\.\\S+', '', cleaned_text)\n",
    "\n",
    "  #remove html tags\n",
    "  cleaned_text = re.sub(r'<.*?>', '', cleaned_text)\n",
    "\n",
    "  #remove non-ascii characters\n",
    "  cleaned_text = ''.join(ch for ch in cleaned_text if ch in string.printable)\n",
    "\n",
    "  #replace abbreviation\n",
    "  cleaned_text = ' '.join(abbreviations[word] if word in abbreviations else word for word in cleaned_text.split())\n",
    "\n",
    "  #substitue @mention with string \"USER\"\n",
    "  cleaned_text = re.sub(r'@\\S+', 'USER', cleaned_text)\n",
    "\n",
    "  #substitute numerics with number \"NUMBER\"\n",
    "  cleaned_text = re.sub(r'\\d+?[.,\\d]*', 'NUMBER', cleaned_text)\n",
    "\n",
    "  #remove emoji's\n",
    "  emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" \n",
    "                           u\"\\U0001F300-\\U0001F5FF\" \n",
    "                           u\"\\U0001F680-\\U0001F6FF\" \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "  cleaned_text = emoji_pattern.sub(r'', cleaned_text)\n",
    "\n",
    "  #remove extra white spaces\n",
    "  cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "  cleaned_text = word_tokenize(cleaned_text)\n",
    "  cleaned_text = [abbreviations[word] if word in abbreviations else word for word in cleaned_text]\n",
    "  cleaned_text = [special_characters[word] if word in special_characters else word for word in cleaned_text]\n",
    "  cleaned_text = [expand_contractions[word] if word in expand_contractions else word for word in cleaned_text]\n",
    "  cleaned_text = [informal_abbreviations[word] if word in informal_abbreviations else word for word in cleaned_text]\n",
    "  cleaned_text = [smileys[word] if word in smileys else word for word in cleaned_text]\n",
    "  cleaned_text = ' '.join([word for word in cleaned_text])\n",
    "    \n",
    "  doc = spacy_en(cleaned_text)\n",
    "  cleaned_text = ' '.join([token.lemma_ for token in doc if token.lemma_ not in ['-PRON-'] and token.pos_ not in ['DET','-PRON']])  \n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:18.058118Z",
     "iopub.status.busy": "2021-02-17T11:19:18.057468Z",
     "iopub.status.idle": "2021-02-17T11:19:18.060370Z",
     "shell.execute_reply": "2021-02-17T11:19:18.059968Z"
    },
    "id": "EzZ_MOm79bmb",
    "papermill": {
     "duration": 0.037934,
     "end_time": "2021-02-17T11:19:18.060476",
     "exception": false,
     "start_time": "2021-02-17T11:19:18.022542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bert needs special token at the front and end\n",
    "def add_special_token(text):\n",
    "  cleaned_text = \"[CLS] \" + text + \" [SEP]\"   \n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:18.129614Z",
     "iopub.status.busy": "2021-02-17T11:19:18.129012Z",
     "iopub.status.idle": "2021-02-17T11:19:39.734032Z",
     "shell.execute_reply": "2021-02-17T11:19:39.733406Z"
    },
    "id": "07z0NOmqSwpv",
    "papermill": {
     "duration": 21.641419,
     "end_time": "2021-02-17T11:19:39.734163",
     "exception": false,
     "start_time": "2021-02-17T11:19:18.092744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = np.vectorize(clean_text)(train_df['text'])\n",
    "train_df['cleaned_text'] = np.vectorize(add_special_token)(train_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:39.803461Z",
     "iopub.status.busy": "2021-02-17T11:19:39.802900Z",
     "iopub.status.idle": "2021-02-17T11:19:39.807023Z",
     "shell.execute_reply": "2021-02-17T11:19:39.806581Z"
    },
    "id": "q9ciIYBhAWEi",
    "papermill": {
     "duration": 0.040209,
     "end_time": "2021-02-17T11:19:39.807144",
     "exception": false,
     "start_time": "2021-02-17T11:19:39.766935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#constants\n",
    "MAX_LEN = 128\n",
    "BATCH_SZ=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:39.878113Z",
     "iopub.status.busy": "2021-02-17T11:19:39.877365Z",
     "iopub.status.idle": "2021-02-17T11:19:39.879643Z",
     "shell.execute_reply": "2021-02-17T11:19:39.880214Z"
    },
    "id": "RWZcxVKJ_W7N",
    "papermill": {
     "duration": 0.040603,
     "end_time": "2021-02-17T11:19:39.880343",
     "exception": false,
     "start_time": "2021-02-17T11:19:39.839740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_input_attention_mask(tweets):   \n",
    "  tokenized_tweets = [bert_tokenizer.tokenize(tweet) for tweet in tweets]\n",
    "  input_ids = [bert_tokenizer.convert_tokens_to_ids(x) for x in tokenized_tweets]\n",
    "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "  attention_masks = []  \n",
    "  for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "  return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:39.953463Z",
     "iopub.status.busy": "2021-02-17T11:19:39.952724Z",
     "iopub.status.idle": "2021-02-17T11:19:43.648621Z",
     "shell.execute_reply": "2021-02-17T11:19:43.648130Z"
    },
    "id": "No_aV_VlhuZ6",
    "papermill": {
     "duration": 3.735853,
     "end_time": "2021-02-17T11:19:43.648748",
     "exception": false,
     "start_time": "2021-02-17T11:19:39.912895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks = generate_input_attention_mask(train_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1kS6hPVMruU",
    "papermill": {
     "duration": 0.032584,
     "end_time": "2021-02-17T11:19:43.714555",
     "exception": false,
     "start_time": "2021-02-17T11:19:43.681971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:43.786286Z",
     "iopub.status.busy": "2021-02-17T11:19:43.785584Z",
     "iopub.status.idle": "2021-02-17T11:19:43.788412Z",
     "shell.execute_reply": "2021-02-17T11:19:43.788009Z"
    },
    "id": "wIy3Rfvb4WOG",
    "papermill": {
     "duration": 0.041697,
     "end_time": "2021-02-17T11:19:43.788519",
     "exception": false,
     "start_time": "2021-02-17T11:19:43.746822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Custom metric f1-score to be used for monitoring\n",
    "def recall(y_true, y_pred):    \n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    predicted_positives = K.sum(K.round(y_pred))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmDAExGMGCLB",
    "papermill": {
     "duration": 0.032724,
     "end_time": "2021-02-17T11:19:43.853493",
     "exception": false,
     "start_time": "2021-02-17T11:19:43.820769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Train - 80% Val - 20% of entire training data available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:43.926998Z",
     "iopub.status.busy": "2021-02-17T11:19:43.925887Z",
     "iopub.status.idle": "2021-02-17T11:19:44.003029Z",
     "shell.execute_reply": "2021-02-17T11:19:44.002525Z"
    },
    "id": "6efWScfXib6c",
    "papermill": {
     "duration": 0.117187,
     "end_time": "2021-02-17T11:19:44.003160",
     "exception": false,
     "start_time": "2021-02-17T11:19:43.885973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_input_ids, train_df['target'], train_size=0.8, random_state=100)\n",
    "train_masks, validation_masks, _, _ = train_test_split(train_attention_masks, train_df['target'], train_size=0.8, random_state=100)\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "validation_inputs = torch.tensor(validation_inputs, dtype=torch.long)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels.values, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:44.077085Z",
     "iopub.status.busy": "2021-02-17T11:19:44.075293Z",
     "iopub.status.idle": "2021-02-17T11:19:44.077691Z",
     "shell.execute_reply": "2021-02-17T11:19:44.078139Z"
    },
    "id": "UHiq6aYCKvUR",
    "papermill": {
     "duration": 0.04205,
     "end_time": "2021-02-17T11:19:44.078272",
     "exception": false,
     "start_time": "2021-02-17T11:19:44.036222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SZ)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:19:44.147228Z",
     "iopub.status.busy": "2021-02-17T11:19:44.146695Z",
     "iopub.status.idle": "2021-02-17T11:20:10.101825Z",
     "shell.execute_reply": "2021-02-17T11:20:10.101389Z"
    },
    "id": "nxmAZsbRK8I_",
    "outputId": "025af72a-3118-4173-f24c-f01743b589c8",
    "papermill": {
     "duration": 25.990671,
     "end_time": "2021-02-17T11:20:10.101953",
     "exception": false,
     "start_time": "2021-02-17T11:19:44.111282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:11<00:00, 34326509.25B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:20:10.238788Z",
     "iopub.status.busy": "2021-02-17T11:20:10.238279Z",
     "iopub.status.idle": "2021-02-17T11:20:10.242150Z",
     "shell.execute_reply": "2021-02-17T11:20:10.241741Z"
    },
    "id": "CyXYtMTtOEv_",
    "outputId": "25bfb198-73f7-4fb6-9bfb-17021df8805a",
    "papermill": {
     "duration": 0.076926,
     "end_time": "2021-02-17T11:20:10.242254",
     "exception": false,
     "start_time": "2021-02-17T11:20:10.165328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=2e-5,\n",
    "                     warmup=.1)\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlxJSD0LOxuM",
    "papermill": {
     "duration": 0.062128,
     "end_time": "2021-02-17T11:20:10.366427",
     "exception": false,
     "start_time": "2021-02-17T11:20:10.304299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:20:10.499169Z",
     "iopub.status.busy": "2021-02-17T11:20:10.498637Z",
     "iopub.status.idle": "2021-02-17T11:26:57.075875Z",
     "shell.execute_reply": "2021-02-17T11:26:57.076304Z"
    },
    "id": "NvtUOfILOw_7",
    "outputId": "57649cb0-299a-4a2b-cecb-83aa5a415909",
    "papermill": {
     "duration": 406.648314,
     "end_time": "2021-02-17T11:26:57.076455",
     "exception": false,
     "start_time": "2021-02-17T11:20:10.428141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.46157938663247994\n",
      "Train loss: 0.2970094054703313\n",
      "Train loss: 0.1845028461664135\n",
      "Train loss: 0.11477488360041022\n"
     ]
    }
   ],
   "source": [
    "train_loss_set = []\n",
    "epochs = 4\n",
    "\n",
    "for _ in range(epochs):  \n",
    "  model.train()  \n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8RKfJ4fO9AO",
    "papermill": {
     "duration": 0.06378,
     "end_time": "2021-02-17T11:26:57.203795",
     "exception": false,
     "start_time": "2021-02-17T11:26:57.140015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:26:57.342556Z",
     "iopub.status.busy": "2021-02-17T11:26:57.341780Z",
     "iopub.status.idle": "2021-02-17T11:27:04.130966Z",
     "shell.execute_reply": "2021-02-17T11:27:04.131560Z"
    },
    "id": "cbq6qxreO8ZZ",
    "outputId": "aef90b3b-fd34-46e8-a371-7bd920a1924d",
    "papermill": {
     "duration": 6.861512,
     "end_time": "2021-02-17T11:27:04.131765",
     "exception": false,
     "start_time": "2021-02-17T11:26:57.270253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8159265350877193\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "eval_accuracy = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "   # Add batch to GPU\n",
    "   batch = tuple(t.to(device) for t in batch)\n",
    "   # Unpack the inputs from our dataloader\n",
    "   b_input_ids, b_input_mask, b_labels = batch\n",
    "   # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "   with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPZxMVVnajdz",
    "papermill": {
     "duration": 0.063225,
     "end_time": "2021-02-17T11:27:04.259515",
     "exception": false,
     "start_time": "2021-02-17T11:27:04.196290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Prediction on test set to be evaluated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:27:04.392611Z",
     "iopub.status.busy": "2021-02-17T11:27:04.391864Z",
     "iopub.status.idle": "2021-02-17T11:27:14.691031Z",
     "shell.execute_reply": "2021-02-17T11:27:14.690563Z"
    },
    "id": "DkN9wCuDDq4Y",
    "papermill": {
     "duration": 10.368239,
     "end_time": "2021-02-17T11:27:14.691170",
     "exception": false,
     "start_time": "2021-02-17T11:27:04.322931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.drop(columns=['keyword', 'location'], inplace=True)\n",
    "test_df['cleaned_text'] = np.vectorize(clean_text)(test_df['text'])\n",
    "test_df['cleaned_text'] = np.vectorize(add_special_token)(test_df['cleaned_text'])\n",
    "test_input_ids, test_attention_masks = generate_input_attention_mask(test_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:27:14.822735Z",
     "iopub.status.busy": "2021-02-17T11:27:14.822010Z",
     "iopub.status.idle": "2021-02-17T11:27:14.843956Z",
     "shell.execute_reply": "2021-02-17T11:27:14.843547Z"
    },
    "id": "dmkLV2ZfegT9",
    "papermill": {
     "duration": 0.08955,
     "end_time": "2021-02-17T11:27:14.844065",
     "exception": false,
     "start_time": "2021-02-17T11:27:14.754515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_inputs = torch.tensor(test_input_ids, dtype=torch.long)\n",
    "test_attention = torch.tensor(test_attention_masks, dtype=torch.long)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_attention)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size = BATCH_SZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:27:14.977505Z",
     "iopub.status.busy": "2021-02-17T11:27:14.976716Z",
     "iopub.status.idle": "2021-02-17T11:27:29.490938Z",
     "shell.execute_reply": "2021-02-17T11:27:29.490060Z"
    },
    "id": "tl4-KyyvStJ5",
    "papermill": {
     "duration": 14.584042,
     "end_time": "2021-02-17T11:27:29.491079",
     "exception": false,
     "start_time": "2021-02-17T11:27:14.907037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_mask = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "    logits = model(b_input_ids, token_type_ids=None, attention_mask = b_mask)\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  predictions.append(logits)\n",
    "\n",
    "test_predictions = [item for sublist in predictions for item in sublist]\n",
    "test_predictions = np.argmax(test_predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T11:27:29.622966Z",
     "iopub.status.busy": "2021-02-17T11:27:29.622037Z",
     "iopub.status.idle": "2021-02-17T11:27:29.734671Z",
     "shell.execute_reply": "2021-02-17T11:27:29.734214Z"
    },
    "id": "CZQ3KnKlteL8",
    "papermill": {
     "duration": 0.180222,
     "end_time": "2021-02-17T11:27:29.734786",
     "exception": false,
     "start_time": "2021-02-17T11:27:29.554564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test_df['id'], 'target':test_predictions})\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3qrvI1Jf2qH",
    "papermill": {
     "duration": 0.062861,
     "end_time": "2021-02-17T11:27:29.861086",
     "exception": false,
     "start_time": "2021-02-17T11:27:29.798225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 519.683423,
   "end_time": "2021-02-17T11:27:32.037225",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-17T11:18:52.353802",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

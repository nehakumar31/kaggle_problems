{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Approach- <br><br>1. Data reading and understanding<br>2. EDA[EDA shown here is only for one specific store and dept, this behavior was observed in most data]<br>3. Data preparation and feature generation<br>4. Data modelling<br> => As evident from EDA plots, seasonality is present, so regression is built with past year sale coming out to be an important feature<br> => FBProphet to capture seasonality automatically<br> => Seasonal differencing and ARIMA(AR1(1)) to capture correlation at lag 1<br>5. Average the predictions from each of the model","metadata":{}},{"cell_type":"code","source":"#All imports\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom zipfile import ZipFile\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n#preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\n#modelling - regression\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n\n#modelling - timeseries\nfrom fbprophet import Prophet\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\n\n#evaluation\nfrom sklearn.metrics import mean_absolute_error","metadata":{"id":"X6MP8WZdEbuR","execution":{"iopub.status.busy":"2021-06-28T08:34:37.347751Z","iopub.execute_input":"2021-06-28T08:34:37.348168Z","iopub.status.idle":"2021-06-28T08:34:37.362363Z","shell.execute_reply.started":"2021-06-28T08:34:37.348136Z","shell.execute_reply":"2021-06-28T08:34:37.361284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SOURCE_PATH='../input/walmart-recruiting-store-sales-forecasting/'","metadata":{"id":"yoZ9JXPaEqzm","execution":{"iopub.status.busy":"2021-06-28T07:06:28.371505Z","iopub.execute_input":"2021-06-28T07:06:28.372023Z","iopub.status.idle":"2021-06-28T07:06:28.377641Z","shell.execute_reply.started":"2021-06-28T07:06:28.37199Z","shell.execute_reply":"2021-06-28T07:06:28.375715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Step 1 - Data Reading and Understanding**","metadata":{"id":"s2vWIifDE309"}},{"cell_type":"code","source":"#extract all the zip files\nfor root, dirs, files in os.walk(SOURCE_PATH):\n    for file_name in files:\n        if(file_name.endswith('.zip')):\n            file_path = SOURCE_PATH + file_name\n            with ZipFile(file_path, 'r') as zip_file_handle:\n                zip_file_handle.extractall()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:06:36.072134Z","iopub.execute_input":"2021-06-28T07:06:36.072937Z","iopub.status.idle":"2021-06-28T07:06:36.353451Z","shell.execute_reply.started":"2021-06-28T07:06:36.072888Z","shell.execute_reply":"2021-06-28T07:06:36.35234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read train data\ntrain_df = pd.read_csv('train.csv')\ntrain_df['Date'] = pd.to_datetime(train_df['Date'], format='%Y-%m-%d')\ntrain_df.head()","metadata":{"id":"ggaxqzcKEzeP","outputId":"75e70bd0-5fdc-4bdb-f6e6-cdd9f7b722fe","execution":{"iopub.status.busy":"2021-06-28T07:06:37.920408Z","iopub.execute_input":"2021-06-28T07:06:37.920836Z","iopub.status.idle":"2021-06-28T07:06:38.290964Z","shell.execute_reply.started":"2021-06-28T07:06:37.9208Z","shell.execute_reply":"2021-06-28T07:06:38.29002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"id":"gcE5avEEE-ap","outputId":"e16887ff-a379-4757-e767-e9d511c03b5b","execution":{"iopub.status.busy":"2021-06-28T07:06:43.124784Z","iopub.execute_input":"2021-06-28T07:06:43.12529Z","iopub.status.idle":"2021-06-28T07:06:43.15092Z","shell.execute_reply.started":"2021-06-28T07:06:43.125242Z","shell.execute_reply":"2021-06-28T07:06:43.150201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_date = train_df['Date'].min()\nmax_date = train_df['Date'].max()\nn_train_samples = train_df.shape[0]\n\nprint (\"Train Data ranges from {} to {}\".format(min_date, max_date))\nprint (\"# of train samples: \", n_train_samples)","metadata":{"id":"OIs0iLC7FDvt","outputId":"59629858-65cf-42cf-a3ef-0b266e66a7c2","execution":{"iopub.status.busy":"2021-06-28T07:06:48.790748Z","iopub.execute_input":"2021-06-28T07:06:48.791933Z","iopub.status.idle":"2021-06-28T07:06:48.807308Z","shell.execute_reply.started":"2021-06-28T07:06:48.79186Z","shell.execute_reply":"2021-06-28T07:06:48.805582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read test data\ntest_df = pd.read_csv('./test.csv')\ntest_df['Date'] = pd.to_datetime(test_df['Date'], format='%Y-%m-%d')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:06:49.999524Z","iopub.execute_input":"2021-06-28T07:06:49.999888Z","iopub.status.idle":"2021-06-28T07:06:50.094583Z","shell.execute_reply.started":"2021-06-28T07:06:49.999857Z","shell.execute_reply":"2021-06-28T07:06:50.093507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_date = test_df['Date'].min()\nmax_date = test_df['Date'].max()\nn_test_samples = test_df.shape[0]\n\nprint (\"Test Data ranges from {} to {}\".format(min_date, max_date))\nprint (\"# of train samples: \", n_test_samples)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T12:54:01.843958Z","iopub.execute_input":"2021-06-26T12:54:01.844429Z","iopub.status.idle":"2021-06-26T12:54:01.851399Z","shell.execute_reply.started":"2021-06-26T12:54:01.844396Z","shell.execute_reply":"2021-06-26T12:54:01.850604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Concatenate train and test data to ease on feature generation**","metadata":{}},{"cell_type":"code","source":"all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\nprint(all_df.shape)\nprint(all_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:07:00.294037Z","iopub.execute_input":"2021-06-28T07:07:00.294411Z","iopub.status.idle":"2021-06-28T07:07:00.319721Z","shell.execute_reply.started":"2021-06-28T07:07:00.294379Z","shell.execute_reply":"2021-06-28T07:07:00.318167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read features data\nfeatures_df = pd.read_csv('features.csv')\nfeatures_df['Date'] = pd.to_datetime(features_df['Date'])\nfeatures_df.head()","metadata":{"id":"VuMkuffyFHfR","outputId":"b436767d-55ee-4d17-d6b1-1b4f494b9015","execution":{"iopub.status.busy":"2021-06-28T07:07:01.554835Z","iopub.execute_input":"2021-06-28T07:07:01.555211Z","iopub.status.idle":"2021-06-28T07:07:01.597231Z","shell.execute_reply.started":"2021-06-28T07:07:01.555165Z","shell.execute_reply":"2021-06-28T07:07:01.595965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Combining Sales,features, stores data on the basis of Store and Date**","metadata":{"id":"HvnI25sHFWSk"}},{"cell_type":"code","source":"all_df = pd.merge(all_df, features_df, how='inner', on=['Store', 'Date', 'IsHoliday'])\nall_df.head()","metadata":{"id":"aJ9zxsAnFQYp","outputId":"83629a05-ef1b-4fb7-cd78-3ff9a4e15822","execution":{"iopub.status.busy":"2021-06-28T07:07:14.862942Z","iopub.execute_input":"2021-06-28T07:07:14.863626Z","iopub.status.idle":"2021-06-28T07:07:15.060015Z","shell.execute_reply.started":"2021-06-28T07:07:14.863565Z","shell.execute_reply":"2021-06-28T07:07:15.058416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read stores data\nstores_df = pd.read_csv(SOURCE_PATH + 'stores.csv')\nstores_df.head()","metadata":{"id":"MwJbTuJhFZF9","outputId":"a86a4241-1a5f-4b4c-f6cf-4e968564397b","execution":{"iopub.status.busy":"2021-06-28T07:07:16.373556Z","iopub.execute_input":"2021-06-28T07:07:16.373935Z","iopub.status.idle":"2021-06-28T07:07:16.399798Z","shell.execute_reply.started":"2021-06-28T07:07:16.373906Z","shell.execute_reply":"2021-06-28T07:07:16.398691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Combining Stores details**","metadata":{"id":"bYa2FZiEFp_x"}},{"cell_type":"code","source":"all_df = pd.merge(all_df, stores_df, how='inner', on='Store')\nall_df.head()","metadata":{"id":"R7I6yXx0FlBi","outputId":"76874d32-d0e7-4780-e71e-57ca7affaac7","execution":{"iopub.status.busy":"2021-06-28T07:07:19.450709Z","iopub.execute_input":"2021-06-28T07:07:19.451351Z","iopub.status.idle":"2021-06-28T07:07:19.578711Z","shell.execute_reply.started":"2021-06-28T07:07:19.4513Z","shell.execute_reply":"2021-06-28T07:07:19.577327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check if any duplicate records with respect to Store and Dept\nall_df[all_df.duplicated(subset=['Store', 'Dept', 'Date'])]","metadata":{"id":"ZM_S9YQgFuSv","outputId":"0ca652f4-2438-433a-f93f-005b26b57f5d","execution":{"iopub.status.busy":"2021-06-28T07:07:24.666835Z","iopub.execute_input":"2021-06-28T07:07:24.667252Z","iopub.status.idle":"2021-06-28T07:07:24.785553Z","shell.execute_reply.started":"2021-06-28T07:07:24.667217Z","shell.execute_reply":"2021-06-28T07:07:24.783564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the distribution of numerical columns like Temperature, FuelPrice..\nall_df[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].describe()","metadata":{"id":"Mkx_MOhjFyp8","outputId":"30881832-46e2-4824-9126-c4de28c5eded","execution":{"iopub.status.busy":"2021-06-28T07:07:26.862856Z","iopub.execute_input":"2021-06-28T07:07:26.863319Z","iopub.status.idle":"2021-06-28T07:07:27.025468Z","shell.execute_reply.started":"2021-06-28T07:07:26.863281Z","shell.execute_reply":"2021-06-28T07:07:27.024338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Step 2 - EDA**","metadata":{"id":"bhOJbz9vGe2W"}},{"cell_type":"markdown","source":"**Extracting few fields to ease on EDA**","metadata":{}},{"cell_type":"code","source":"#Extracting Year, Month, Date\nall_df['Year'] = all_df['Date'].dt.year\nall_df['Month'] = all_df['Date'].dt.month\nall_df['WeekNumber'] = all_df['Date'].dt.week\n\n#Extracting WeekendNumber for each month\nall_df['WeekendNumber'] = all_df.groupby(by=['Store','Year','Month'])['Date'].rank(method='dense').astype('int')\nall_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:45:18.31545Z","iopub.execute_input":"2021-06-28T07:45:18.315875Z","iopub.status.idle":"2021-06-28T07:45:18.619085Z","shell.execute_reply.started":"2021-06-28T07:45:18.315843Z","shell.execute_reply":"2021-06-28T07:45:18.6179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Distribution of Weekly_Sales**","metadata":{"id":"aXXUvUgwCq6h"}},{"cell_type":"code","source":"sns.distplot(all_df['Weekly_Sales'])\nplt.show()","metadata":{"id":"xDIhR44yCwB4","outputId":"c598c230-c759-4e98-dd14-56da515393a5","execution":{"iopub.status.busy":"2021-06-28T07:07:34.147969Z","iopub.execute_input":"2021-06-28T07:07:34.148791Z","iopub.status.idle":"2021-06-28T07:07:36.23429Z","shell.execute_reply.started":"2021-06-28T07:07:34.148724Z","shell.execute_reply":"2021-06-28T07:07:36.232786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the distribution plot, data is highly skewed. Also, Scaling would be needed for regression to bring features on same values range**","metadata":{}},{"cell_type":"markdown","source":"**For further EDA, taking just one store, one department data. The same can be repeated for others too**","metadata":{}},{"cell_type":"code","source":"store_1_dep_1_df = all_df[(all_df.Store ==1) & (all_df.Dept==1)]\nprint(store_1_dep_1_df.shape)\nstore_1_dep_1_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:51:17.493158Z","iopub.execute_input":"2021-06-28T07:51:17.493637Z","iopub.status.idle":"2021-06-28T07:51:17.575227Z","shell.execute_reply.started":"2021-06-28T07:51:17.493592Z","shell.execute_reply":"2021-06-28T07:51:17.573572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Overall sales plot to see if any trend present\nplt.plot(store_1_dep_1_df['Date'], store_1_dep_1_df['Weekly_Sales'])\nplt.title(\"3 yr Sales of Store 1 and Dept 1\")\nplt.xticks(rotation=45)\nplt.show()\n\n#Sales for each year to capture any seasonality\nyr=2010\nwhile(yr<=2012):\n    sales_per_year = store_1_dep_1_df[store_1_dep_1_df.Year==yr]\n    plt.plot(sales_per_year['Date'], sales_per_year['Weekly_Sales'])\n    plt.title(\"Sales of Store 1 and Dept 1 - Year {}\".format(yr))\n    plt.xticks(rotation=45)\n    plt.show()\n    \n    yr+=1","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:28:43.567391Z","iopub.execute_input":"2021-06-28T07:28:43.567792Z","iopub.status.idle":"2021-06-28T07:28:44.471666Z","shell.execute_reply.started":"2021-06-28T07:28:43.56776Z","shell.execute_reply":"2021-06-28T07:28:44.470475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There is no apparent trend but certainly there is seasonality. And the peaks corresponding to Holiday season - Feb(Superbowl), Nov(Thanksgiving), Dec(Christmas Month)**","metadata":{}},{"cell_type":"markdown","source":"**December month has a special behavior - Sales are high on all weekends before Christmas eve. This can be seen from plot and values**","metadata":{}},{"cell_type":"code","source":"print(\"Year - 2010\", store_1_dep_1_df[(store_1_dep_1_df.Year==2010) & (store_1_dep_1_df.Month==12)]['Weekly_Sales'])\nprint(\"Year - 2011\", store_1_dep_1_df[(store_1_dep_1_df.Year==2011) & (store_1_dep_1_df.Month==12)]['Weekly_Sales'])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T07:59:06.604Z","iopub.execute_input":"2021-06-28T07:59:06.604646Z","iopub.status.idle":"2021-06-28T07:59:06.620963Z","shell.execute_reply.started":"2021-06-28T07:59:06.604609Z","shell.execute_reply":"2021-06-28T07:59:06.618744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6,4))\n\nplt.plot(store_1_dep_1_df[(store_1_dep_1_df.Year==2010) & (store_1_dep_1_df.Month==12)]['WeekendNumber'], store_1_dep_1_df[(store_1_dep_1_df.Year==2010) & (store_1_dep_1_df.Month==12)]['Weekly_Sales'], label='2010')\nplt.plot(store_1_dep_1_df[(store_1_dep_1_df.Year==2011) & (store_1_dep_1_df.Month==12)]['WeekendNumber'], store_1_dep_1_df[(store_1_dep_1_df.Year==2011) & (store_1_dep_1_df.Month==12)]['Weekly_Sales'], label='2011')\nplt.xticks([1,2,3,4,5])\nplt.legend(loc='upper right')    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:07:03.571768Z","iopub.execute_input":"2021-06-28T08:07:03.572382Z","iopub.status.idle":"2021-06-28T08:07:04.031078Z","shell.execute_reply.started":"2021-06-28T08:07:03.572269Z","shell.execute_reply":"2021-06-28T08:07:04.029395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Step 3 - Data Preparation**","metadata":{"id":"u-riG5xDG4UT"}},{"cell_type":"markdown","source":"**Replacing column: Type and Size with an ordered numeric indicator about the size of column<br>A/1 => Big stores, B/2 => Medium size stores, C/3 => Small stores**","metadata":{"id":"C8GTBAURHWVE"}},{"cell_type":"code","source":"all_df['StoreSize'] = all_df['Type'].map({'A':1, 'B':2, 'C':3})\nall_df.drop(columns=['Type', 'Size'], inplace=True)\n\nall_df.head()","metadata":{"id":"rH4ZSGPLHs2t","outputId":"d995a848-9d8d-4b47-c5d9-571db14f7100","execution":{"iopub.status.busy":"2021-06-28T08:10:39.441712Z","iopub.execute_input":"2021-06-28T08:10:39.442095Z","iopub.status.idle":"2021-06-28T08:10:39.609141Z","shell.execute_reply.started":"2021-06-28T08:10:39.44206Z","shell.execute_reply":"2021-06-28T08:10:39.608283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Drop columns => Temperature, Fuel_Price, MarkDown*, CPI, Unemployment**","metadata":{"id":"P6BiDbVpLw61"}},{"cell_type":"code","source":"cols_to_drop = [c for c in all_df.columns if c[0:8] == 'MarkDown']\ncols_to_drop.extend(['Temperature', 'Fuel_Price', 'CPI', 'Unemployment'])\nall_df.drop(columns=cols_to_drop, inplace=True)\nall_df.head()","metadata":{"id":"LBlN_EWnG3kj","outputId":"63607770-5659-474f-ae0f-2c1f5662882d","execution":{"iopub.status.busy":"2021-06-28T08:10:48.133861Z","iopub.execute_input":"2021-06-28T08:10:48.134567Z","iopub.status.idle":"2021-06-28T08:10:48.181486Z","shell.execute_reply.started":"2021-06-28T08:10:48.134507Z","shell.execute_reply":"2021-06-28T08:10:48.180291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create new columns from IsHoliday as indicator for days when sales are high.<br>IsSuperbowl => superbowl weekend<br>IsThanksgiving => Thanksgiving weekend<br>IsChristmasMonth => weekends prior to christmas weekend**","metadata":{"id":"Gyrht6isL2GP"}},{"cell_type":"code","source":"#Sales are high on superbowl weekend\nall_df['IsSuperbowl'] = 0\nall_df.loc[all_df['Date'].isin(['2010-02-12','2011-02-11','2012-02-10','2013-02-08']),'IsSuperbowl'] = 1\n\n#Sales are high on Thanksgiving weekend\nall_df['IsThanksgiving'] = 0\nall_df.loc[all_df['Date'].isin(['2010-11-26','2011-11-25','2012-11-23','2013-11-29']), 'IsThanksgiving'] = 1\n\n#Sales are high in month of december on all weekends prior to christmas weekend\nall_df['IsChristmasMonth'] = 0\nall_df.loc[(all_df['Month']==12) & (all_df['Year']==2010) & (all_df['Date'] < '2010-12-31'), 'IsChristmasMonth'] = 1\nall_df.loc[(all_df['Month']==12) & (all_df['Year']==2011) & (all_df['Date'] < '2011-12-30'), 'IsChristmasMonth'] = 1\nall_df.loc[(all_df['Month']==12) & (all_df['Year']==2012) & (all_df['Date'] < '2012-12-28'), 'IsChristmasMonth'] = 1\nall_df.loc[(all_df['Month']==12) & (all_df['Year']==2013) & (all_df['Date'] < '2013-12-27'), 'IsChristmasMonth'] = 1","metadata":{"id":"uAynWFn7LaIs","execution":{"iopub.status.busy":"2021-06-28T08:10:53.054609Z","iopub.execute_input":"2021-06-28T08:10:53.055228Z","iopub.status.idle":"2021-06-28T08:10:53.151211Z","shell.execute_reply.started":"2021-06-28T08:10:53.055172Z","shell.execute_reply":"2021-06-28T08:10:53.149726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From EDA, Sales are high on weekend in the beginning of the month. In case, first weekend falls on 1st or 2nd of the month, then sales would be high on next weekend.**","metadata":{"id":"1kpiCHP7xs4M"}},{"cell_type":"code","source":"#Pull out Date and WeekendNumber to decide on high sales weekend and this can be later merged with all_df\ndef isHighSaleWeekend(row):\n  if row['WeekendNumber'] == 1 and row['Date'].date().day < 3:\n    return 0\n  elif row['WeekendNumber'] == 1 and row['Date'].date().day >= 3:\n    return 1\n  elif row['WeekendNumber'] == 2 and ( (row['Date'].date().day==8)  or (row['Date'].date().day==9) ):\n    return 1\n  else:\n    return 0\n\nall_date_df = all_df[['Date', 'WeekendNumber']]\nall_date_df.drop_duplicates(inplace=True, ignore_index=True)\nall_date_df['IsHighSaleWeekend'] = all_date_df.apply(isHighSaleWeekend, axis=1)\nall_date_df.head()","metadata":{"id":"Z8nWbxjL1tj7","outputId":"cb658a9d-0cd4-43cc-eaf6-87bb7f10dbac","execution":{"iopub.status.busy":"2021-06-28T08:11:13.344443Z","iopub.execute_input":"2021-06-28T08:11:13.344825Z","iopub.status.idle":"2021-06-28T08:11:13.45041Z","shell.execute_reply.started":"2021-06-28T08:11:13.344793Z","shell.execute_reply":"2021-06-28T08:11:13.449237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding IsHighSaleWeekend feature to indicate high sales in beginning of the month\nall_df = pd.merge(all_df, all_date_df, on=['Date','WeekendNumber'], how='inner')\nall_df.head() ","metadata":{"id":"oaumbyh20MHL","outputId":"16a47a1b-b074-4956-ec8b-69affa83e3e2","execution":{"iopub.status.busy":"2021-06-28T08:11:23.416574Z","iopub.execute_input":"2021-06-28T08:11:23.417003Z","iopub.status.idle":"2021-06-28T08:11:23.615302Z","shell.execute_reply.started":"2021-06-28T08:11:23.41697Z","shell.execute_reply":"2021-06-28T08:11:23.613809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As evident from plot above that data has seasonality, so adding past year sale as feature corresponding to Store, Dept**","metadata":{"id":"OfNjfnjHjnzJ"}},{"cell_type":"code","source":"all_grouped_df = all_df.groupby(['Store','Dept','Year'])\nall_keys = all_grouped_df.groups.keys()\ndone = set()\nfor k in all_keys:\n    if (k[0], k[1]) not in done:\n        s = k[0]\n        d = k[1]\n        yr = 2011        \n        while(yr <= 2013):            \n            try:\n                sales_yr = all_grouped_df.get_group((k[0],k[1],yr))\n                sales_past_yr = all_grouped_df.get_group((k[0],k[1],yr-1))\n                \n                for _,row in sales_yr.iterrows():\n                    week_number = row['WeekNumber']\n                    last_yr_sale = sales_past_yr[sales_past_yr.WeekNumber==week_number]['Weekly_Sales']                    \n                    if(len(last_yr_sale) > 0):\n                        all_df.loc[(all_df.Store==s) & (all_df.Dept==d) & (all_df.Year==yr) & (all_df.WeekNumber==week_number), 'Weekly_Sales_past1yr'] =  last_yr_sale.values[0]                        \n            except KeyError as exc:\n                print(exc)\n                \n            yr+=1\n                \n        done.add((k[0], k[1]))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T08:28:50.064503Z","iopub.execute_input":"2021-06-26T08:28:50.065014Z","iopub.status.idle":"2021-06-26T09:29:22.681402Z","shell.execute_reply.started":"2021-06-26T08:28:50.06497Z","shell.execute_reply":"2021-06-26T09:29:22.680592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For Year 2010 and till WeekNumber of 5 for Year 2011, no past year data is available so not considering them for imputation of past year sales** ","metadata":{}},{"cell_type":"code","source":"all_with_missing_df = all_df[~(all_df.Year==2010)]\nall_with_missing_df = all_with_missing_df[~((all_df.Year==2011) & (all_df.WeekNumber < 5))]\nall_with_missing_df = all_with_missing_df[all_with_missing_df['Weekly_Sales_past1yr'].isnull()]\nall_with_missing_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-26T09:35:15.392681Z","iopub.execute_input":"2021-06-26T09:35:15.393029Z","iopub.status.idle":"2021-06-26T09:35:15.516983Z","shell.execute_reply.started":"2021-06-26T09:35:15.393Z","shell.execute_reply":"2021-06-26T09:35:15.515519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#iterate over each row and use average to impute the missing past year sale\n#first compute average sale of past year, same month for corresponding store and dept\n#if not present, then compute average of all data for past year for corresponding store and dept\n#else substitute with 0\n\nfor _, row in all_with_missing_df.iterrows():\n    s = row['Store']\n    d = row['Dept']\n    y = row['Year']\n    m = row['Month']\n    w = row['WeekNumber']\n    \n    past_sale = all_df[(all_df.Store==s) & (all_df.Dept==d) & (all_df.Year==y-1) & (all_df.Month==m)]['Weekly_Sales']           \n    if(len(past_sale) > 0 and not np.isnan(past_sale.mean())):\n        all_df.loc[(all_df.Store==s) & (all_df.Dept==d) & (all_df.Year==y) & (all_df.Month==m) & (all_df.WeekNumber==w), 'Weekly_Sales_past1yr'] = past_sale.mean()                \n    else:\n        past_sale = all_df[(all_df.Store==s) & (all_df.Dept==d) & (all_df.Year==y-1)]['Weekly_Sales']        \n        if(len(past_sale) > 0 and not np.isnan(past_sale.mean())):\n            all_df.loc[(all_df.Store==s) & (all_df.Dept==d) & (all_df.Year==y) & (all_df.Month==m) & (all_df.WeekNumber==w), 'Weekly_Sales_past1yr'] = past_sale.mean()            \n        else:            \n            all_df.loc[(all_df.Store==s) & (all_df.Dept==d) & (all_df.Year==y) & (all_df.Month==m) & (all_df.WeekNumber==w), 'Weekly_Sales_past1yr'] = 0                                        ","metadata":{"execution":{"iopub.status.busy":"2021-06-26T09:35:21.759162Z","iopub.execute_input":"2021-06-26T09:35:21.75956Z","iopub.status.idle":"2021-06-26T09:38:54.743222Z","shell.execute_reply.started":"2021-06-26T09:35:21.759526Z","shell.execute_reply":"2021-06-26T09:38:54.741856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T12:55:31.745772Z","iopub.execute_input":"2021-06-26T12:55:31.746347Z","iopub.status.idle":"2021-06-26T12:55:31.820532Z","shell.execute_reply.started":"2021-06-26T12:55:31.746312Z","shell.execute_reply":"2021-06-26T12:55:31.819697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Step5 - Data Modelling**","metadata":{"id":"m4tChnfeGLFs"}},{"cell_type":"code","source":"#helper function to compute weighted mean absolute error\ndef compute_weighted_mae(true, pred, weight):\n    return mean_absolute_error(y_true=true, y_pred=pred, sample_weight = weight)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T12:55:40.708336Z","iopub.execute_input":"2021-06-26T12:55:40.708942Z","iopub.status.idle":"2021-06-26T12:55:40.712925Z","shell.execute_reply.started":"2021-06-26T12:55:40.708906Z","shell.execute_reply":"2021-06-26T12:55:40.712153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To bring features on same scale, so using StandardScaler\nscaler = StandardScaler()\nall_df[['Weekly_Sales_Scaled']] = scaler.fit_transform(all_df[['Weekly_Sales']])\nall_df[['Weekly_Sales_Past1yr_Scaled']] = scaler.fit_transform(all_df[['Weekly_Sales_past1yr']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split train and test data\ntrain_data = all_df.loc[0:n_train_samples-1]\ntrain_data = train_data[~(train_data.Year==2010)]   #Discard 2010 data as there is no information on past yr sales\ntrain_data = train_data[~( (train_data.Year==2011) & (train_data.WeekNumber < 5) )] #No data from year 2010 prior to WeekNumber 5\n\ntest_data = all_df.loc[n_train_samples:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model 1 - Linear Regression**","metadata":{"id":"CfxeoRzzGO-b"}},{"cell_type":"code","source":"#prepare train and validation data\nX = train_data[['StoreSize', 'IsSuperbowl', 'IsThanksgiving', 'IsChristmasMonth','IsHighSaleWeekend','Weekly_Sales_Past1yr_Scaled']]\ny = train_data['Weekly_Sales_Scaled']\n\nn_split = int(len(X)*0.8)\nX_train, X_val = X[0:n_split], X[n_split:]\ny_train, y_val = y[0:n_split], y[n_split:]\nX_train_weight = train_data['IsHoliday'][0:n_split].map({True:5, False:1})\nX_val_weight = train_data['IsHoliday'][n_split:].map({True:5, False:1})\n\nprint(\"# of training samples: \", len(X_train))\nprint(\"# of validation samples: \", len(X_val))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:03:58.737351Z","iopub.execute_input":"2021-06-26T17:03:58.737713Z","iopub.status.idle":"2021-06-26T17:03:58.86348Z","shell.execute_reply.started":"2021-06-26T17:03:58.73768Z","shell.execute_reply":"2021-06-26T17:03:58.862414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit linear regression on train split data\nX_train_sm = sm.add_constant(X_train)\nlr_model = sm.OLS(y_train, X_train).fit()\nprint(lr_model.summary())","metadata":{"id":"002KTkCxF-CU","outputId":"4b20514a-238e-4c1f-fe81-b7e7ee86b520","execution":{"iopub.status.busy":"2021-06-26T17:04:04.297505Z","iopub.execute_input":"2021-06-26T17:04:04.297896Z","iopub.status.idle":"2021-06-26T17:04:04.465918Z","shell.execute_reply.started":"2021-06-26T17:04:04.297861Z","shell.execute_reply":"2021-06-26T17:04:04.462906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From R-square, 96.6% of variance can be explained by this model**","metadata":{}},{"cell_type":"code","source":"#run predictions on train and val data and compute weighted mean\ny_train_pred = lr_model.predict(X_train)\ny_train_inv = scaler.inverse_transform(y_train.values.reshape(-1,1))\ny_train_pred_inv = scaler.inverse_transform(y_train_pred.values.reshape(-1,1))\ntrain_wmae = compute_weighted_mae(y_train_inv[:,0], y_train_pred_inv[:,0], X_train_weight)\nprint(\"Train wmae: \", train_wmae)\n\ny_val_inv = scaler.inverse_transform(y_val.values.reshape(-1,1))\ny_val_pred = lr_model.predict(X_val)\ny_val_pred_inv = scaler.inverse_transform(y_val_pred.values.reshape(-1,1))\nval_wmae = compute_weighted_mae(y_val_inv, y_val_pred_inv, X_val_weight)\nprint(\"Validation wmae: \", val_wmae)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:04:24.51383Z","iopub.execute_input":"2021-06-26T17:04:24.514187Z","iopub.status.idle":"2021-06-26T17:04:24.539425Z","shell.execute_reply.started":"2021-06-26T17:04:24.514155Z","shell.execute_reply":"2021-06-26T17:04:24.536736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test Prediction**","metadata":{}},{"cell_type":"code","source":"X_test = test_data[['StoreSize', 'IsSuperbowl', 'IsThanksgiving', 'IsChristmasMonth','IsHighSaleWeekend','Weekly_Sales_Past1yr_Scaled']]\n\nprint(\"# of samples in test data: \", X_test.shape[0])\n\ny_test_pred = lr_model.predict(X_test)\nlr_predictions = scaler.inverse_transform(y_test_pred.values.reshape(-1,1))\ntest_data['Predicted_Sales_reg'] = lr_predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:43.801584Z","iopub.execute_input":"2021-06-26T17:05:43.801949Z","iopub.status.idle":"2021-06-26T17:05:43.83041Z","shell.execute_reply.started":"2021-06-26T17:05:43.801915Z","shell.execute_reply":"2021-06-26T17:05:43.829256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model 2 - TimeSeries using FbProphet**","metadata":{}},{"cell_type":"code","source":"test_data['Predicted_Sales_fbprophet'] = np.nan\n\nprint(\"# of training samples: \", len(train_data))\nprint(\"# of testing samples: \", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T13:12:18.106875Z","iopub.execute_input":"2021-06-26T13:12:18.107234Z","iopub.status.idle":"2021-06-26T13:12:18.181787Z","shell.execute_reply.started":"2021-06-26T13:12:18.107204Z","shell.execute_reply":"2021-06-26T13:12:18.180793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_sales(store_dept_data, store_dept_test):\n    s = store_dept_data['Store'].values[0]\n    d = store_dept_data['Dept'].values[0]\n    \n    if(len(store_dept_data) < 2):\n        print(\"There are less than 2 records for store:{} and dept:{}, skipping prediction\".format(s,d))\n        return\n    \n    store_dept_train = store_dept_data[['Date','Weekly_Sales','IsSuperbowl','IsThanksgiving',\n                                        'IsChristmasMonth','IsHighSaleWeekend','Weekly_Sales_past1yr']]\n    store_dept_train.rename(columns={'Date':'ds', 'Weekly_Sales':'y'}, inplace=True)\n        \n    store_dept_test.rename(columns={'Date':'ds'}, inplace=True)\n    store_dept_test.reset_index(inplace=True, drop=True)\n    \n    #holidays = store_dept_data[store_dept_data['IsHoliday']==True]['Date']\n    #holidays_df = pd.DataFrame({'holiday':'festive season', 'ds':holidays})\n    \n    prophet = Prophet(yearly_seasonality=True, weekly_seasonality=True, interval_width=0.95)\n    prophet.add_regressor('IsSuperbowl')\n    prophet.add_regressor('IsThanksgiving')\n    prophet.add_regressor('IsChristmasMonth')\n    prophet.add_regressor('IsHighSaleWeekend')\n    prophet.add_regressor('Weekly_Sales_past1yr')\n    \n    try:\n        prophet.fit(store_dept_train)\n        forecast = prophet.predict(store_dept_test)\n        predictions = forecast['yhat']\n        for i in range(len(store_dept_test)):          \n            yr = store_dept_test.loc[i,'Year']\n            mth = store_dept_test.loc[i,'Month']\n            wn = store_dept_test.loc[i,'WeekNumber']\n\n            test_data.loc[((test_data.Store==s) & (test_data.Dept==d) & (test_data.Year==yr) & (test_data.Month==mth) & (test_data.WeekNumber==wn)),'Predicted_Sales_fbprophet'] = predictions[i]             \n    except:\n        print(\"Exception processing store:{} and dept: {}\".format(s,d))        ","metadata":{"execution":{"iopub.status.busy":"2021-06-26T13:14:28.408948Z","iopub.execute_input":"2021-06-26T13:14:28.409431Z","iopub.status.idle":"2021-06-26T13:14:28.420346Z","shell.execute_reply.started":"2021-06-26T13:14:28.4094Z","shell.execute_reply":"2021-06-26T13:14:28.419556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_grouped_data = test_data.groupby(['Store','Dept'])\ntrain_grouped_data = train_data.groupby(['Store','Dept'])\n\nfor key in train_grouped_data.groups.keys():\n    if key in test_grouped_data.groups.keys():\n        predict_sales(train_grouped_data.get_group(key), test_grouped_data.get_group(key))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T13:14:34.693625Z","iopub.execute_input":"2021-06-26T13:14:34.694115Z","iopub.status.idle":"2021-06-26T16:40:30.592292Z","shell.execute_reply.started":"2021-06-26T13:14:34.694085Z","shell.execute_reply":"2021-06-26T16:40:30.591201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model 3 - ARIMA**","metadata":{}},{"cell_type":"code","source":"test_data['Predicted_Sales_arima'] = np.nan\n\nprint(\"# of training samples: \", len(train_data))\nprint(\"# of testing samples: \", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T16:43:30.093369Z","iopub.execute_input":"2021-06-26T16:43:30.093722Z","iopub.status.idle":"2021-06-26T16:43:30.1452Z","shell.execute_reply.started":"2021-06-26T16:43:30.093691Z","shell.execute_reply":"2021-06-26T16:43:30.144185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using data of Store 1 and Dept 1 to decide on ARIMA order**","metadata":{}},{"cell_type":"code","source":"#Perform seasonal differencing and check ACF, PACF\nstore_1_dept_1_df['Differenced_Sales'] = store_1_dept_1_df['Weekly_Sales'] - store_1_dept_1_df['Weekly_Sales_past1yr']\n\n#test to check if time series is stationary\nresult = adfuller(store_1_dept_1_df['Differenced_Sales'])\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print(\"{}:{}\".format(key, value))\n    \n#plots to check if any level of correlation is present with lags\nplot_acf(store_1_dept_1_df['Differenced_Sales'])\nplt.show()\n\nplot_pacf(store_1_dept_1_df['Differenced_Sales'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:40:05.733811Z","iopub.execute_input":"2021-06-28T08:40:05.734242Z","iopub.status.idle":"2021-06-28T08:40:05.759826Z","shell.execute_reply.started":"2021-06-28T08:40:05.734208Z","shell.execute_reply":"2021-06-28T08:40:05.757812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As positive correlation is present, using AR1 to consider the same**","metadata":{}},{"cell_type":"code","source":"def predict_sales_arima(store_dept_data, train_order, store_dept_test):\n    s = store_dept_data['Store'].values[0]\n    d = store_dept_data['Dept'].values[0]\n        \n    store_dept_test.reset_index(inplace=True, drop=True)\n        \n    #seasonal differencing to make time series stationary\n    diff = store_dept_data['Weekly_Sales'] - store_dept_data['Weekly_Sales_past1yr']        \n    \n    try:\n        model = ARIMA(diff, order=train_order)\n        model_fit = model.fit(trend='nc')\n    except:\n        print(\"Exception fitting ARIMA on store:{} and dept:{}, so skipping\".format(s,d))\n        return\n    #print(model_fit.summary())\n    \n    pred_start_idx = len(store_dept_data)\n    pred_end_idx = len(store_dept_data) + len(store_dept_test)-1\n    \n    test_predictions = model_fit.predict(start=pred_start_idx, end=pred_end_idx, dynamic=True)    \n    test_predictions.reset_index(inplace=True, drop=True)\n            \n    for i in range(len(store_dept_test)):        \n        test_predictions[i] += store_dept_test.loc[i,'Weekly_Sales_past1yr']\n        \n        yr = store_dept_test.loc[i,'Year']\n        mth = store_dept_test.loc[i,'Month']\n        wn = store_dept_test.loc[i,'WeekNumber']\n        test_data.loc[((test_data.Store==s) & (test_data.Dept==d) & (test_data.Year==yr) & (test_data.Month==mth) & (test_data.WeekNumber==wn)),'Predicted_Sales_arima'] = test_predictions[i]             ","metadata":{"execution":{"iopub.status.busy":"2021-06-26T16:51:04.875266Z","iopub.execute_input":"2021-06-26T16:51:04.875629Z","iopub.status.idle":"2021-06-26T16:51:04.887361Z","shell.execute_reply.started":"2021-06-26T16:51:04.875599Z","shell.execute_reply":"2021-06-26T16:51:04.885994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_grouped_data = test_data.groupby(['Store','Dept'])\ntrain_grouped_data = train_data.groupby(['Store','Dept'])\nstore_dept_data = train_grouped_data.get_group((1,1))\n\nfor key in train_grouped_data.groups.keys():\n    if key in test_grouped_data.groups.keys():\n        predict_sales_arima(train_grouped_data.get_group(key), (1,0,0), test_grouped_data.get_group(key))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:25:51.640527Z","iopub.execute_input":"2021-06-28T08:25:51.641049Z","iopub.status.idle":"2021-06-28T08:25:51.646563Z","shell.execute_reply.started":"2021-06-28T08:25:51.641014Z","shell.execute_reply":"2021-06-28T08:25:51.64515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Step 6 - Submission**","metadata":{}},{"cell_type":"code","source":"def compute_average_sales(row):\n    values = [row['Predicted_Sales_reg']]\n    \n    if not np.isnan(row['Predicted_Sales_fbprophet']):\n        values.append(row['Predicted_Sales_fbprophet'])        \n        \n    if not np.isnan(row['Predicted_Sales_arima']):\n        values.append(row['Predicted_Sales_arima'])\n        \n    return np.mean(values) ","metadata":{"execution":{"iopub.status.busy":"2021-06-27T11:52:47.510186Z","iopub.execute_input":"2021-06-27T11:52:47.510648Z","iopub.status.idle":"2021-06-27T11:52:47.517659Z","shell.execute_reply.started":"2021-06-27T11:52:47.510605Z","shell.execute_reply":"2021-06-27T11:52:47.516631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#combining the results of regression ,arima and fbprophet\ntest_data['Final_Predicted_Sales'] = test_data.apply(lambda x:compute_average_sales(x), axis=1)    \nprint(test_data.shape)\nprint(test_data.head())\n    \nid = test_data.apply(lambda row:str(row['Store']) + \"_\" + str(row['Dept']) + \"_\" + (row['Date']), axis=1)\nsubmission_df = pd.DataFrame({'Id':id, 'Weekly_Sales':test_data['Final_Predicted_Sales']})    \nprint(submission_df.shape)\nprint(submission_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-27T11:52:50.419417Z","iopub.execute_input":"2021-06-27T11:52:50.419946Z","iopub.status.idle":"2021-06-27T11:52:59.948078Z","shell.execute_reply.started":"2021-06-27T11:52:50.419896Z","shell.execute_reply":"2021-06-27T11:52:59.947068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('./Submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T11:54:48.897786Z","iopub.execute_input":"2021-06-27T11:54:48.89813Z","iopub.status.idle":"2021-06-27T11:54:49.339048Z","shell.execute_reply.started":"2021-06-27T11:54:48.8981Z","shell.execute_reply":"2021-06-27T11:54:49.33794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}